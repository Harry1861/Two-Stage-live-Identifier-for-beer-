{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7bbf08-20fd-409e-ae36-4588f546850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# more info on callbakcs: https://keras.io/callbacks/ model saver is cool too.\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d380802b-b951-43a6-a579-2fc2fab5f4cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-conv-25-nodes-0-dense-1717639654\n",
      "\u001b[1m295/295\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 48ms/step - accuracy: 0.8017 - loss: 0.4328 - val_accuracy: 0.9193 - val_loss: 0.2106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load X and y from pickle files\n",
    "with open(\"X.pickle\", \"rb\") as file:\n",
    "    X = pickle.load(file)\n",
    "\n",
    "with open(\"y.pickle\", \"rb\") as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Normalize the input data\n",
    "X = X / 255.0\n",
    "\n",
    "dense_layers = [0]\n",
    "layer_sizes = [25]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs2epoch\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(X, y,\n",
    "                      batch_size=20,\n",
    "                      epochs=1,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[tensorboard])\n",
    "\n",
    "model.save('25x2x0.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "913cca24-83da-4f17-9ce4-88881f19b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Beer\", \"Plastic\"]  # will use this to convert prediction num to string value\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 100  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize image to match model's expected sizing\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # return the image with shaping that TF wants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fa55b4f-06c6-4873-93aa-387f59f84cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"50x1x0.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85f13254-ed1d-4e42-bf07-68991f73b8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "Plastic\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare(r'C:\\Users\\Administrator\\Desktop\\Computer Vision\\Project\\check data\\plastic\\20_jpg.rf.c637a9b24f96f2671be1e011ee189a6b.jpg')])  # REMEMBER YOU'RE PASSING A LIST OF THINGS YOU WISH TO PREDICT\n",
    "print(CATEGORIES[int(prediction[0][0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fd0277b-6de9-4184-9eb5-17d38bafbe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Predicted: Plastic | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Predicted: Beer | Actual: Beer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Beer | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Predicted: Beer | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Beer | Actual: Plastic\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Predicted: Plastic | Actual: Plastic\n",
      "Accuracy for Beer: 66.08%\n",
      "Accuracy for Plastic: 82.35%\n",
      "Total Accuracy: 67.55%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Beer\", \"Plastic\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 100\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "def load_and_predict(model, folder_path):\n",
    "    correct_predictions = {category: 0 for category in CATEGORIES}\n",
    "    total_images = {category: 0 for category in CATEGORIES}\n",
    "    total_correct_predictions = 0\n",
    "    total_images_count = 0\n",
    "    \n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(folder_path, category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = prepare(os.path.join(path, img))\n",
    "                prediction = model.predict(img_array)\n",
    "                predicted_label = CATEGORIES[int(prediction[0][0])]\n",
    "                actual_label = category\n",
    "                print(\"Predicted:\", predicted_label, \"| Actual:\", actual_label)\n",
    "                if predicted_label == actual_label:\n",
    "                    correct_predictions[category] += 1\n",
    "                    total_correct_predictions += 1\n",
    "                total_images[category] += 1\n",
    "                total_images_count += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    accuracy_per_class = {category: (correct_predictions[category] / total_images[category] * 100) for category in CATEGORIES}\n",
    "    total_accuracy = (total_correct_predictions / total_images_count) * 100\n",
    "    return accuracy_per_class, total_accuracy\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(\"25x2x0.keras\")\n",
    "# Path to the directory containing the image data\n",
    "data_path = r'C:\\Users\\Administrator\\Desktop\\Computer Vision\\Project\\check data'\n",
    "# Calculate accuracy per class and display predictions\n",
    "accuracy_per_class, total_accuracy = load_and_predict(model, data_path)\n",
    "for category, accuracy in accuracy_per_class.items():\n",
    "    print(f\"Accuracy for {category}: {accuracy:.2f}%\")\n",
    "print(f\"Total Accuracy: {total_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630d7aa6-596e-4c7c-a409-3c4801d91d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow_hub) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow_hub) (3.20.3)\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow_hub)\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (23.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow_hub) (0.1.0)\n",
      "Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 660.6 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.7 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.4/1.7 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: tf-keras, tensorflow_hub\n",
      "Successfully installed tensorflow_hub-0.16.1 tf-keras-2.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "389b25f0-0b3c-4017-9222-1770e0afbac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 690.7ms\n",
      "Speed: 16.0ms preprocess, 690.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mputText(frame, classNames[\u001b[38;5;28mcls\u001b[39m], (x1, y1), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.9\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Display the frame\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject Detection\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Check for 'q' key press to quit\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\patches.py:56\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(winname, mat)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(winname: \u001b[38;5;28mstr\u001b[39m, mat: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    Displays an image in the specified window.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m        mat (np.ndarray): Image to be shown.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     _imshow(winname\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124municode_escape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(), mat)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO model\n",
    "checkpoint_path = r\"C:\\Users\\Administrator\\Desktop\\Computer Vision\\Project\\detection\\train\\weights\\best.pt\"\n",
    "model = YOLO(checkpoint_path)\n",
    "\n",
    "# Object classes\n",
    "classNames = [\"Bottle\"]\n",
    "\n",
    "# Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "            cv2.putText(frame, classNames[cls], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    # Check for 'q' key press to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7b30f45-2213-41f2-ab8a-fa945f6eed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\administrator\\anaconda3\\lib\\site-packages (4.10.0.82)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7e9e556-b92d-4d2f-a35d-43cc0e78c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 195.5ms\n",
      "Speed: 6.0ms preprocess, 195.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 51\u001b[0m\n\u001b[0;32m     47\u001b[0m         thickness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     49\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mputText(img, classNames[\u001b[38;5;28mcls\u001b[39m], org, font, fontScale, color, thickness)\n\u001b[1;32m---> 51\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWebcam\u001b[39m\u001b[38;5;124m'\u001b[39m, img)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ultralytics\\utils\\patches.py:56\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(winname, mat)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(winname: \u001b[38;5;28mstr\u001b[39m, mat: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    Displays an image in the specified window.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m        mat (np.ndarray): Image to be shown.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m     _imshow(winname\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124municode_escape\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(), mat)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "# start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# model\n",
    "checkpoint_path = r\"C:\\Users\\Administrator\\Desktop\\Computer Vision\\Project\\detection\\train\\weights\\best.pt\"\n",
    "model = YOLO(checkpoint_path)\n",
    "\n",
    "# object classes\n",
    "classNames = [\"Bottle\"\n",
    "              ]\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # coordinates\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            # bounding box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "            # put box in cam\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "\n",
    "            # confidence\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # class name\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # object details\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0)\n",
    "            thickness = 2\n",
    "\n",
    "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4fa0cfc-3543-4309-8164-17050cc52595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Corrected lists with equal lengths\n",
    "actual = [\n",
    "    'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer',\n",
    "    'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer',\n",
    "    'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer',\n",
    "    'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer',\n",
    "    'Beer', 'Beer', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic',\n",
    "    'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic'\n",
    "]\n",
    "predicted = [\n",
    "    'Beer', 'Beer', 'Plastic', 'Beer', 'Beer', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Beer',\n",
    "    'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Plastic', 'Beer', 'Plastic', 'Plastic', 'Plastic',\n",
    "    'Plastic', 'Plastic', 'Beer', 'Beer', 'Plastic', 'Beer', 'Beer', 'Beer', 'Beer', 'Beer', 'Plastic',\n",
    "    'Plastic', 'Beer', 'Beer', 'Plastic', 'Plastic', 'Beer', 'Beer', 'Beer', 'Beer', 'Plastic', 'Beer',\n",
    "    'Beer', 'Plastic', 'Beer', 'Plastic', 'Plastic', 'Beer', 'Plastic', 'Plastic', 'Plastic', 'Plastic',\n",
    "    'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic', 'Plastic'\n",
    "]\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(actual, predicted, labels=['Beer', 'Plastic'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Beer', 'Plastic'], yticklabels=['Beer', 'Plastic'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f518d6-85ea-4fdc-afa2-1aaabebb8103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
